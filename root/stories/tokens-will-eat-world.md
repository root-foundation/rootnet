---
title: tokens will eat the world
---
to understand why, we need to first study how our world will change.

## artificial intelligence

fundamentally, i view artificial intelligence as a tool that enables us to express ourselves better. and that [ai will never replace us](/ai-will-never-replace-us).

as ai improves, we will naturally gravitate towards more creative and complex work - across the board - because ai will do the simpler, less creative work for us.

## extreme outcomes

but the more creative and complex our work becomes, the more extreme outcomes we will see across our economy:

at any given moment, a tiny (and shrinking) percentage of people, companies, networks, etc. will be responsible for the majority of value created. (i.e, power law distribution of outcomes).

creative, complex work and extreme outcomes go hand in hand. we can't have one without the other. we already see extreme outcomes in our world today in highly creative, complex work (startups, content creation, arts, science, etc.).

what will be new is extreme outcomes across the board, because ai will do the simpler work across the board. ai doesn't distinguish between domains and labels like we do. all ai cares about complexity, it doesn't care if the task in "music" or "programming" or anything. therefore, we will us ai in everything we do.

extreme outcomes just represents what most of us intuitively know: for any creative activity, there exist people that are just way better than the rest.

**extreme outcomes is natural.**

## dynamism

extreme outcomes on its own paints a sort of dystopian picture.

if ai makes outcomes more extreme, will that lead to a world with like... 10 people who create all the value and no one else can?

absolutely not.

we fail to see what extreme outcomes means without also seeing _dynamism_:

firstly, the peak outcome rises. the most valuable companies today are worth much more than the most value companies a few decades ago. we will see the peak outcome skyrocket much faster than ever before. what this means is that even smaller wins feel much bigger in the same way that today a millionaire can afford a lot even though their share relative to the richest person has fallen. we will have many more "winners".

secondly, the rate of displacement increases because ai accelerates the rate of change of our world. for example, all the top companies today are more fragile than ever before because of a breakthrough that fundamentally changed the world, that they can't adapt well to. as such breakthroughs from unpredictable areas increasingly shake our world up, existing winners will find it very difficult to hold onto their positions.

similarly, when a new breakthrough occurs somewhere, we will push resources very rapidly to incredible ideas that such breakthrough has enabled.

this is what a _dynamic_ world with extreme outcomes looks like. i believe we will see a world in which ideas will generate trillions in revenue days after being launched, and become outcompeted within months because of some random breakthrough elsewhere that invalidated their approach entirely.

it is a world in which we react to a rapidly changing reality blazingly fast.

such dynamism is key for our progress.

and with the right financial system, such a world benefits all of us.

extreme outcomes _without_ dynamism points at a rotten system: unfairness. oppression. favoritism. political influence. we should be very suspicious when we see stagnation in the system.

stagnation is unnatural.

## we will securitize everything

as ai makes outcomes extreme, we will securitize everything we do.

a security is a shared structure that lets many people coordinate around something uncertain. 

the simplest example is a company. a company isn’t just a product or a team - it’s a structure that lets us pool talent, attention, and capital toward something that doesn’t fully exist yet.

once we wrap something in a security, we can:
- allocate resources to it.
- share upside from its success.
- and adapt quickly as reality changes. 

securities exist at different levels of abstraction. the personal token exists at a higher level of abstraction than a company because it is grounded in equities in companies. similarly, we will cover another security later that sits above personal tokens.

and as ai pushes our work into more creative & complex territory that have far more extreme outcomes, we’ll securitize every expression, at all levels of abstraction.

we will have tokens for everything.

## personal tokens will be used broadly

the more creative and complex our work becomes, the more outcomes become extreme, the more we securitize our world, the more broadly personal tokens will be used.

in the early days, personal tokens will be primarily used by those in the "startup" world - those who want to get involved with companies by starting, working at, or investing in them - because personal tokens are grounded in equities in companies.

eventually we will see everyone - artists, creators, musicians, scientists, politicians, etc. - all use personal tokens to incentivize help, because personal tokens will be grounded in every expression that has extreme outcomes (to capture a person's upside).

## our current system is outdated

while extreme outcomes are natural, our current financial system is not set up for it. we will needlessly suffer unless we adapt. in the next section, we'll design a better system for our world that enables all of us to gain from extreme outcomes.